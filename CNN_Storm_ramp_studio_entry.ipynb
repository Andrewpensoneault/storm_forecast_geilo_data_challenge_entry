{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN-Storm_ramp_studio_entry.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andrewpensoneault/storm_forecast_geilo_data_challenge_entry/blob/master/CNN_Storm_ramp_studio_entry.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "m6PgR9yDstFp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Initial necessity\n",
        "import os\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bSs7a9DstSNl",
        "colab_type": "code",
        "outputId": "6655942b-62ac-4ea8-a431-0c37502541c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Get data and files from drive (or from githib if comment the first two lines and uncomment the rest)\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/My Drive/storm_forecast')\n",
        "# !git clone https://github.com/ramp-kits/storm_forecast\n",
        "# os.chdir('/storm_forecast')\n",
        "# !pip install -r requirements.txt\n",
        "# !python download_data.py\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sla2SUrjsuFA",
        "colab_type": "code",
        "outputId": "dfd61c99-00a4-43cf-835f-5ee2c9eeb9de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "# Setup the necessary libraries and get data\n",
        "!pip install git+https://github.com/paris-saclay-cds/ramp-workflow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/paris-saclay-cds/ramp-workflow\n",
            "  Cloning https://github.com/paris-saclay-cds/ramp-workflow to /tmp/pip-req-build-ug6nlmab\n",
            "Requirement already satisfied (use --upgrade to upgrade): ramp-workflow==0.2.0+49.gc22e3ee from git+https://github.com/paris-saclay-cds/ramp-workflow in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ramp-workflow==0.2.0+49.gc22e3ee) (1.14.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from ramp-workflow==0.2.0+49.gc22e3ee) (1.1.0)\n",
            "Requirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.6/dist-packages (from ramp-workflow==0.2.0+49.gc22e3ee) (0.22.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from ramp-workflow==0.2.0+49.gc22e3ee) (0.20.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from ramp-workflow==0.2.0+49.gc22e3ee) (0.6.1)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->ramp-workflow==0.2.0+49.gc22e3ee) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->ramp-workflow==0.2.0+49.gc22e3ee) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2->pandas>=0.19.2->ramp-workflow==0.2.0+49.gc22e3ee) (1.11.0)\n",
            "Building wheels for collected packages: ramp-workflow\n",
            "  Running setup.py bdist_wheel for ramp-workflow ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-rwoyffez/wheels/35/a2/c3/7969a73ddfefc0dcad3709cb7a81f52fb90348df9bb9b8c455\n",
            "Successfully built ramp-workflow\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XVfXRtsZshk0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Feature Training Class\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "class FeatureExtractor(object):\n",
        "    def __init__(self):\n",
        "        self.scalar_fields = ['instant_t', 'windspeed', 'latitude', 'longitude',\n",
        "                       'hemisphere', 'Jday_predictor', 'initial_max_wind',\n",
        "                       'max_wind_change_12h', 'dist2land']\n",
        "        self.spatial_fields = [\"u\", \"v\", \"sst\", \"slp\", \"hum\",\"z\",\"vo700\"]\n",
        "        self.scaling_values = pd.DataFrame(index=self.spatial_fields,\n",
        "                                           columns=[\"mean\", \"std\"], dtype=float)\n",
        "        self.scalar_norm = MinMaxScaler()\n",
        "\n",
        "    def fit(self, X_df, y):\n",
        "        field_grids = []\n",
        "        self.y_max = np.amax(np.array(y))\n",
        "        self.y_min = np.amin(np.array(y))\n",
        "        for field in self.spatial_fields:\n",
        "            f_cols = X_df.columns[X_df.columns.str.contains(field + \"_\")]\n",
        "            f_data = X_df[f_cols].values.reshape(-1, 11, 11)\n",
        "            field_grids.append(f_data)\n",
        "        for f, field in enumerate(self.spatial_fields):\n",
        "            self.scaling_values.loc[field, \"mean\"] = np.nanmean(field_grids[f])\n",
        "            self.scaling_values.loc[field, \"std\"] = np.nanstd(field_grids[f])\n",
        "            self.scaling_values.loc[field, \"min\"] = np.nanmin(field_grids[f])\n",
        "            self.scaling_values.loc[field, \"max\"] = np.nanmax(field_grids[f])\n",
        "        self.scalar_norm.fit(X_df[self.scalar_fields])\n",
        "\n",
        "    def transform(self, X_df):\n",
        "        field_grids = []\n",
        "        for field in self.spatial_fields:\n",
        "            f_cols = X_df.columns[X_df.columns.str.contains(field + \"_\")]\n",
        "            f_data = X_df[f_cols].values.reshape(-1, 11, 11)\n",
        "            field_grids.append((f_data - self.scaling_values.loc[field, \"min\"]) / ( self.scaling_values.loc[field, \"max\"]- self.scaling_values.loc[field, \"min\"]))\n",
        "            field_grids[-1][np.isnan(field_grids[-1])] = 0\n",
        "        norm_data = np.stack(field_grids, axis=-1)\n",
        "        norm_scalar = self.scalar_norm.transform(X_df[self.scalar_fields])\n",
        "        return [[norm_data, norm_scalar], self.y_max, self.y_min]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P2i_8340soe2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Concatenate, Dropout, BatchNormalization, Conv2D, Activation, Dense, Input, MaxPooling2D, Flatten, Dropout, PReLU, ReLU\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.regularizers import l1\n",
        "from sklearn.base import BaseEstimator\n",
        "from keras.optimizers import RMSprop, Nadam, Adam, SGD\n",
        "\n",
        "import numpy as np\n",
        "class Regressor(BaseEstimator):\n",
        "    def __init__(self):\n",
        "        # define model\n",
        "        l1_weight = 0.002\n",
        "        model_in = Input(shape=(11, 11, 7))\n",
        "        scalar_in = Input(shape=(9,)) \n",
        " \n",
        "        model = Conv2D(36, (5, 5), padding=\"same\")(model_in)\n",
        "        model = PReLU()(model)\n",
        "        model = MaxPooling2D()(model)\n",
        " \n",
        "        model = Conv2D(128, (3,3), padding=\"same\")(model)\n",
        "        model = PReLU()(model)\n",
        "        model = MaxPooling2D()(model)\n",
        " \n",
        "        model = Conv2D(192, (3,3), padding=\"same\")(model)\n",
        "        model = PReLU()(model)\n",
        "        model = Flatten()(model)\n",
        " \n",
        "        model = Dense(256, kernel_regularizer=l1(l1_weight))(model)\n",
        "        model = PReLU()(model)\n",
        " \n",
        "        model = Concatenate()([model, scalar_in])\n",
        " \n",
        "        model = Dense(64, kernel_regularizer=l1(l1_weight))(model)\n",
        "        model = PReLU()(model)\n",
        " \n",
        "        model = Dense(32, kernel_regularizer=l1(l1_weight))(model)\n",
        "        model = PReLU()(model)\n",
        "      \n",
        "        model = Dense(16, kernel_regularizer=l1(l1_weight))(model)\n",
        "        model = PReLU()(model)\n",
        "        \n",
        "        model = Dense(1)(model)        \n",
        " \n",
        "        self.cnn_model = Model([model_in, scalar_in], model)\n",
        "        self.cnn_model.compile(loss=\"mse\", optimizer=Adam())\n",
        " \n",
        "        self.cnn_model.summary()\n",
        "        return\n",
        "    def fit(self, X, y):\n",
        "        X, y_max, y_min = X\n",
        "        _, x = X\n",
        "        self.y_max = y_max\n",
        "        self.y_min = y_min\n",
        "        y = (y-y_min)/(y_max-y_min) - x[:,1]\n",
        "        callback = [EarlyStopping(min_delta=0.0001, patience=10)]\n",
        "        self.cnn_model.fit(X, y, epochs=200, batch_size=200, verbose=1, callbacks=callback, validation_split = .1)\n",
        "    \n",
        "    def predict(self, X): \n",
        "        X, _, _ = X\n",
        "        _, x = X\n",
        "        return (self.cnn_model.predict(X).ravel() + x[:,1])*(self.y_max-self.y_min)+self.y_min\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nbyi3Ehcs6T_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Gets the Data\n",
        "from problem import get_train_data, get_test_data\n",
        "data_train, y_train = get_train_data()\n",
        "data_test, y_test = get_test_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "2c702296-6b4f-451c-97de-e77c7ba10868",
        "id": "a58OZGbJjqoN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1915
        }
      },
      "cell_type": "code",
      "source": [
        "#Train the Model\n",
        "training_features = FeatureExtractor()\n",
        "training_features.fit(data_train, y_train)\n",
        "X = training_features.transform(data_train)\n",
        "reg = Regressor()\n",
        "reg.fit(X, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
            "  return self.partial_fit(X, y)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_25 (InputLayer)           (None, 11, 11, 7)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 11, 11, 36)   6336        input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_84 (PReLU)              (None, 11, 11, 36)   4356        conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_25 (MaxPooling2D) (None, 5, 5, 36)     0           p_re_lu_84[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 5, 5, 128)    41600       max_pooling2d_25[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_85 (PReLU)              (None, 5, 5, 128)    3200        conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_26 (MaxPooling2D) (None, 2, 2, 128)    0           p_re_lu_85[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 2, 2, 192)    221376      max_pooling2d_26[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_86 (PReLU)              (None, 2, 2, 192)    768         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_13 (Flatten)            (None, 768)          0           p_re_lu_86[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_59 (Dense)                (None, 256)          196864      flatten_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_87 (PReLU)              (None, 256)          256         dense_59[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_26 (InputLayer)           (None, 9)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 265)          0           p_re_lu_87[0][0]                 \n",
            "                                                                 input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_60 (Dense)                (None, 64)           17024       concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_88 (PReLU)              (None, 64)           64          dense_60[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_61 (Dense)                (None, 32)           2080        p_re_lu_88[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_89 (PReLU)              (None, 32)           32          dense_61[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_62 (Dense)                (None, 16)           528         p_re_lu_89[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_90 (PReLU)              (None, 16)           16          dense_62[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_63 (Dense)                (None, 1)            17          p_re_lu_90[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 494,517\n",
            "Trainable params: 494,517\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Train on 14199 samples, validate on 1578 samples\n",
            "Epoch 1/200\n",
            "14199/14199 [==============================] - 20s 1ms/step - loss: 7.5368 - val_loss: 1.2643\n",
            "Epoch 2/200\n",
            "14199/14199 [==============================] - 16s 1ms/step - loss: 0.5708 - val_loss: 0.2461\n",
            "Epoch 3/200\n",
            "14199/14199 [==============================] - 16s 1ms/step - loss: 0.1709 - val_loss: 0.1150\n",
            "Epoch 4/200\n",
            "14199/14199 [==============================] - 16s 1ms/step - loss: 0.0923 - val_loss: 0.0783\n",
            "Epoch 5/200\n",
            "14199/14199 [==============================] - 16s 1ms/step - loss: 0.0729 - val_loss: 0.0689\n",
            "Epoch 6/200\n",
            "14199/14199 [==============================] - 17s 1ms/step - loss: 0.0686 - val_loss: 0.0676\n",
            "Epoch 7/200\n",
            "14199/14199 [==============================] - 16s 1ms/step - loss: 0.0677 - val_loss: 0.0669\n",
            "Epoch 8/200\n",
            "14199/14199 [==============================] - 16s 1ms/step - loss: 0.0672 - val_loss: 0.0667\n",
            "Epoch 9/200\n",
            "14199/14199 [==============================] - 16s 1ms/step - loss: 0.0668 - val_loss: 0.0665\n",
            "Epoch 10/200\n",
            "14199/14199 [==============================] - 16s 1ms/step - loss: 0.0668 - val_loss: 0.0664\n",
            "Epoch 11/200\n",
            "14199/14199 [==============================] - 16s 1ms/step - loss: 0.0667 - val_loss: 0.0662\n",
            "Epoch 12/200\n",
            "14199/14199 [==============================] - 16s 1ms/step - loss: 0.0667 - val_loss: 0.0663\n",
            "Epoch 13/200\n",
            "14199/14199 [==============================] - 16s 1ms/step - loss: 0.0667 - val_loss: 0.0663\n",
            "Epoch 14/200\n",
            "14199/14199 [==============================] - 16s 1ms/step - loss: 0.0667 - val_loss: 0.0662\n",
            "Epoch 15/200\n",
            "14199/14199 [==============================] - 16s 1ms/step - loss: 0.0668 - val_loss: 0.0660\n",
            "Epoch 16/200\n",
            "14199/14199 [==============================] - 16s 1ms/step - loss: 0.0667 - val_loss: 0.0662\n",
            "Epoch 17/200\n",
            "14199/14199 [==============================] - 16s 1ms/step - loss: 0.0667 - val_loss: 0.0665\n",
            "Epoch 18/200\n",
            "14199/14199 [==============================] - 16s 1ms/step - loss: 0.0668 - val_loss: 0.0664\n",
            "Epoch 19/200\n",
            "14199/14199 [==============================] - 16s 1ms/step - loss: 0.0667 - val_loss: 0.0664\n",
            "Epoch 20/200\n",
            "14199/14199 [==============================] - 16s 1ms/step - loss: 0.0667 - val_loss: 0.0659\n",
            "Epoch 21/200\n",
            "14199/14199 [==============================] - 16s 1ms/step - loss: 0.0668 - val_loss: 0.0663\n",
            "Epoch 22/200\n",
            "14199/14199 [==============================] - 16s 1ms/step - loss: 0.0667 - val_loss: 0.0662\n",
            "Epoch 23/200\n",
            "14199/14199 [==============================] - 16s 1ms/step - loss: 0.0668 - val_loss: 0.0666\n",
            "Epoch 24/200\n",
            "14199/14199 [==============================] - 16s 1ms/step - loss: 0.0667 - val_loss: 0.0663\n",
            "Epoch 25/200\n",
            "14199/14199 [==============================] - 17s 1ms/step - loss: 0.0668 - val_loss: 0.0662\n",
            "Epoch 26/200\n",
            "14199/14199 [==============================] - 16s 1ms/step - loss: 0.0667 - val_loss: 0.0663\n",
            "Epoch 27/200\n",
            "14199/14199 [==============================] - 16s 1ms/step - loss: 0.0667 - val_loss: 0.0660\n",
            "Epoch 28/200\n",
            "14199/14199 [==============================] - 16s 1ms/step - loss: 0.0667 - val_loss: 0.0664\n",
            "Epoch 29/200\n",
            "14199/14199 [==============================] - 16s 1ms/step - loss: 0.0668 - val_loss: 0.0665\n",
            "Epoch 30/200\n",
            "14199/14199 [==============================] - 16s 1ms/step - loss: 0.0667 - val_loss: 0.0664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Udw2CyGXjsgq",
        "colab_type": "code",
        "outputId": "a96b7eee-122b-499b-f857-3a96617c497b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#Testing Results\n",
        "X = training_features.transform(data_test)\n",
        "print('The RMSE of the test dataset is %2.3f' % np.sqrt(np.mean((reg.predict(X)-y_test)**2)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The RMSE of the test dataset is 20.003\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}