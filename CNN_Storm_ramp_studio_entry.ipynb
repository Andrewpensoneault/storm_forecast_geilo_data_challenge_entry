{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN-Storm_ramp_studio_entry.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "m6PgR9yDstFp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Initial necessity\n",
        "import os\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bSs7a9DstSNl",
        "colab_type": "code",
        "outputId": "7b4cb12c-e342-4b67-8f87-23608c665bbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Get data and files from drive (or from githib if comment the first two lines and uncomment the rest)\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/My Drive/storm_forecast')\n",
        "# !git clone https://github.com/ramp-kits/storm_forecast\n",
        "# os.chdir('/storm_forecast')\n",
        "# !pip install -r requirements.txt\n",
        "# !python download_data.py\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sla2SUrjsuFA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "e8c54017-aada-4f72-975c-010583010613"
      },
      "cell_type": "code",
      "source": [
        "# Setup the necessary libraries and get data\n",
        "!pip install git+https://github.com/paris-saclay-cds/ramp-workflow"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/paris-saclay-cds/ramp-workflow\n",
            "  Cloning https://github.com/paris-saclay-cds/ramp-workflow to /tmp/pip-req-build-gnphr0ks\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ramp-workflow==0.2.0+49.gc22e3ee) (1.14.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from ramp-workflow==0.2.0+49.gc22e3ee) (1.1.0)\n",
            "Requirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.6/dist-packages (from ramp-workflow==0.2.0+49.gc22e3ee) (0.22.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from ramp-workflow==0.2.0+49.gc22e3ee) (0.20.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from ramp-workflow==0.2.0+49.gc22e3ee) (0.6.1)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->ramp-workflow==0.2.0+49.gc22e3ee) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->ramp-workflow==0.2.0+49.gc22e3ee) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2->pandas>=0.19.2->ramp-workflow==0.2.0+49.gc22e3ee) (1.11.0)\n",
            "Building wheels for collected packages: ramp-workflow\n",
            "  Running setup.py bdist_wheel for ramp-workflow ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-08de0e_a/wheels/35/a2/c3/7969a73ddfefc0dcad3709cb7a81f52fb90348df9bb9b8c455\n",
            "Successfully built ramp-workflow\n",
            "Installing collected packages: ramp-workflow\n",
            "Successfully installed ramp-workflow-0.2.0+49.gc22e3ee\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XVfXRtsZshk0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Feature Training Class\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "class FeatureExtractor(object):\n",
        "    def __init__(self):\n",
        "        self.scalar_fields = ['instant_t', 'windspeed', 'latitude', 'longitude',\n",
        "                       'hemisphere', 'Jday_predictor', 'initial_max_wind',\n",
        "                       'max_wind_change_12h', 'dist2land']\n",
        "        self.spatial_fields = [\"u\", \"v\", \"sst\", \"slp\", \"hum\",\"z\",\"vo700\"]\n",
        "        self.scaling_values = pd.DataFrame(index=self.spatial_fields,\n",
        "                                           columns=[\"mean\", \"std\"], dtype=float)\n",
        "        self.scalar_norm = MinMaxScaler()\n",
        "\n",
        "    def fit(self, X_df, y):\n",
        "        field_grids = []\n",
        "        self.y_max = np.amax(np.array(y))\n",
        "        self.y_min = np.amin(np.array(y))\n",
        "        for field in self.spatial_fields:\n",
        "            f_cols = X_df.columns[X_df.columns.str.contains(field + \"_\")]\n",
        "            f_data = X_df[f_cols].values.reshape(-1, 11, 11)\n",
        "            field_grids.append(f_data)\n",
        "        for f, field in enumerate(self.spatial_fields):\n",
        "            self.scaling_values.loc[field, \"mean\"] = np.nanmean(field_grids[f])\n",
        "            self.scaling_values.loc[field, \"std\"] = np.nanstd(field_grids[f])\n",
        "            self.scaling_values.loc[field, \"min\"] = np.nanmin(field_grids[f])\n",
        "            self.scaling_values.loc[field, \"max\"] = np.nanmax(field_grids[f])\n",
        "        self.scalar_norm.fit(X_df[self.scalar_fields])\n",
        "\n",
        "    def transform(self, X_df):\n",
        "        field_grids = []\n",
        "        for field in self.spatial_fields:\n",
        "            f_cols = X_df.columns[X_df.columns.str.contains(field + \"_\")]\n",
        "            f_data = X_df[f_cols].values.reshape(-1, 11, 11)\n",
        "            field_grids.append((f_data - self.scaling_values.loc[field, \"min\"]) / ( self.scaling_values.loc[field, \"max\"]- self.scaling_values.loc[field, \"min\"]))\n",
        "            field_grids[-1][np.isnan(field_grids[-1])] = 0\n",
        "        norm_data = np.stack(field_grids, axis=-1)\n",
        "        norm_scalar = self.scalar_norm.transform(X_df[self.scalar_fields])\n",
        "        return [[norm_data, norm_scalar], self.y_max, self.y_min]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P2i_8340soe2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Regressor Class\n",
        "from keras.layers import Concatenate, Dropout, BatchNormalization, Conv2D, Activation, Dense, Input, MaxPooling2D, Flatten, Dropout, PReLU\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.regularizers import l1, l2, l1_l2\n",
        "from sklearn.base import BaseEstimator\n",
        "from keras.optimizers import RMSprop, Nadam, Adam, SGD\n",
        "\n",
        "import numpy as np\n",
        "class Regressor(BaseEstimator):\n",
        "    def __init__(self):\n",
        "        # define model\n",
        "        l2_weight = 0.002\n",
        "        l1_weight = 0.002\n",
        "        model_in = Input(shape=(11, 11, 7))\n",
        "        scalar_in = Input(shape=(9,)) \n",
        " \n",
        "        model = BatchNormalization()(model_in)\n",
        "        model = Conv2D(36, (5, 5), padding=\"same\")(model)\n",
        "        model = PReLU()(model)\n",
        "        model = MaxPooling2D()(model)\n",
        " \n",
        "        model = BatchNormalization()(model)\n",
        "        model = Conv2D(128, (3,3), padding=\"same\")(model)\n",
        "        model = PReLU()(model)\n",
        " \n",
        "        model = MaxPooling2D()(model)\n",
        "        model = BatchNormalization()(model)\n",
        "        model = Conv2D(192, (3,3), padding=\"same\")(model)\n",
        "        model = PReLU()(model)\n",
        "        model = Flatten()(model)\n",
        " \n",
        "        model = Dense(256, kernel_regularizer=l1_l2(l1_weight,l2_weight))(model)\n",
        "        model = PReLU()(model)\n",
        " \n",
        "        model = Concatenate()([model, scalar_in, scalar_in, scalar_in])\n",
        "        model = BatchNormalization()(model)\n",
        " \n",
        "        model = Dense(64, kernel_regularizer=l1_l2(l1_weight,l2_weight))(model)\n",
        "        model = PReLU()(model)\n",
        " \n",
        "        model = Dense(32, kernel_regularizer=l1_l2(l1_weight,l2_weight))(model)\n",
        "        model = PReLU()(model)\n",
        "      \n",
        "        model = Dense(16, kernel_regularizer=l1_l2(l1_weight,l2_weight))(model)\n",
        "        model = PReLU()(model)\n",
        "        \n",
        "        model = Dense(16, kernel_regularizer=l1_l2(l1_weight,l2_weight))(model)\n",
        "        model = PReLU()(model)\n",
        "        \n",
        "        model = Dense(1)(model)        \n",
        " \n",
        "        self.cnn_model = Model([model_in, scalar_in], model)\n",
        "        self.cnn_model.compile(loss=\"mse\", optimizer=Adam())\n",
        " \n",
        "        print(self.cnn_model.summary())\n",
        "        return\n",
        "    def fit(self, X, y):\n",
        "        X, y_max, y_min = X\n",
        "        _, x = X\n",
        "        self.y_max = y_max\n",
        "        self.y_min = y_min\n",
        "        y = (y-y_min)/(y_max-y_min) - x[:,1]\n",
        "        callback = [EarlyStopping(monitor='val_loss', min_delta=.001, patience=10)]\n",
        "        self.cnn_model.fit(X, y, epochs=100, batch_size=200, verbose=1, validation_split = .1, callbacks = callback)\n",
        "    \n",
        "    def predict(self, X): \n",
        "        X, y_max, y_min = X\n",
        "        _ , x = X\n",
        "        return (self.cnn_model.predict(X).ravel() + x[:,1])*(self.y_max-self.y_min)+self.y_min\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nbyi3Ehcs6T_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Gets the Data\n",
        "from problem import get_train_data, get_test_data\n",
        "data_train, y_train = get_train_data()\n",
        "data_test, y_test = get_test_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "a58OZGbJjqoN",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Train the Model\n",
        "training_features = FeatureExtractor()\n",
        "training_features.fit(data_train, y_train)\n",
        "X = training_features.transform(data_train)\n",
        "reg = Regressor()\n",
        "reg.fit(X, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Udw2CyGXjsgq",
        "colab_type": "code",
        "outputId": "ef7802e9-8340-41fb-8c8c-2c7ca90a62c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#Testing Results\n",
        "X = training_features.transform(data_test)\n",
        "print('The RMSE of the test dataset is %2.3f' % np.sqrt(np.mean((reg.predict(X)-y_test)**2)))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The RMSE of the test dataset is 20.007\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}